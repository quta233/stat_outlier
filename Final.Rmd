---
title: "An Analysis of Different Outlier Detection Methods"
author: "Alex Khater, Tina Liu"
date: "2020/1/23"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(sn)
library(Stat2Data)
library(mosaic)
library(car)
library(outliers)
library(moments)
```

**Introduction:** 


The goal of this research project is to compare the outputs of different methods of outlier detection on a variety of different datasets and will attempt to draw conclusions about the relative conservativeness of a given outlier test on data sets of certain distributions and sizes. 

We randomly selected 30 real-world datasets from various experiments and studies and inserted 9 control of each size: Small (x<70), Medium(70<x<500), Large(500<x) and of the 3 common distribution types of the sample: Right Skew, Normal, and Left Skew. We ran 5 Outlier tests on them (R functions will be shown below) :


Chi Square: The Chi square test utilizes the mean divided by the variance and analyzes the most extreme value, outputting a p-value to show its likelihood of being an outlier.

```{r}
chi_square <- function (x, pvalue = 0.03, opposite = FALSE) {
    x <- sort(x[complete.cases(x)])
    variance <- var(x)
    mea <- mean(x)
    n <- length(x)
    i <- 1
    pval <- chisq.out.test(x, opposite = opposite)$p.value
    num <- -1
    while(pval < pvalue) {
      if (xor(((x[n] - mea) < (mea - x[i])), opposite)) {
        alt = paste("lowest value", x[i], "is an outlier")
        chi <- (mea - x[i])^2/variance
        i <- i + 1
        }
      else {
        alt = paste("highest value", x[n], "is an outlier")
        chi <- (x[n] - mea)^2/variance
        n <- n - 1
        }
      pval <- 1 - pchisq(chi, 1)
      print(alt)
      num <- num + 1
    }
    print(num)
}
```


Cook’s Distance: This test measures the Cook’s Distance of each point, a measure of influence, and isolates any point with more than 4 times the mean cook’s distance as an outlier.

```{r}
cook_distance <- function(lm) {
  cooksd <- cooks.distance(lm)
  k <- 4*mean(cooksd)
  data <- data.frame(id=as.character(1:length(cooksd)), 
                  value=cooksd, 
                  stringsAsFactors=F)
  data %>%
    mutate(id = seq.int(nrow(data))) %>%
    mutate(outlier = if_else(value >= k, "yes", "no")) %>%
    filter(outlier == "yes")
}
```

1.5 IQR: This uses the interquartile range (Q3 - Q1) and creates a boundary 1.5 * IQR below Q1 and 1.5* IQR above Q3 to isolate outliers.

```{r}
IQR_test <- function(data, num, v) {
  str <- unname(quantile(num, probs = c(0.25, 0.75), na.rm = TRUE)[c("25%", "75%")])
  iqr <- str[2] - str[1]
  q1 <- str[1] - 1.5*iqr
  q3 <- str[2] + 1.5*iqr
  data %>%
    mutate(id = seq.int(nrow(data))) %>%
    select(id, v) %>%
    rename("value" = v) %>%
    mutate(outlier = if_else(value >= q3 | value <= q1, "yes", "no")) %>%
    filter(outlier == "yes")
}
```

2.5 SD: This uses the standard deviation to create a boundary 2.5 standard deviations above and below the mean.

```{r}
sd_test <- function(data, num, v) {
  t1 <- mean(num) + 2.5*sd(num)
  t2 <- mean(num) - 2.5*sd(num)
  data %>%
    mutate(id = seq.int(nrow(data))) %>%
    select(id, v) %>%
    rename("value" = v) %>%
    mutate(outlier = if_else(value >= t1 | value <= t2, "yes", "no")) %>%
    filter(outlier == "yes")
}
```

Bonferroni: A test that comes in the outliers R package, it analyzes the most extreme value, extracts a p-value and applies the Bonferroni correction to create a p-value adjusted for the sample size.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
cabinet_5 <- read_csv("cabinet-turnover.csv")
cabinet_5 <- cabinet_5 %>%
  mutate(length = as.numeric(length)) %>% 
  filter(!is.na(length))
```


Examples of each test:

Fig. 1: Example dataset:

```{r, echo=FALSE, message=FALSE}
data("SATGPA")
D6<-lm(MathSAT~1, data=SATGPA)
SATGPA %>% 
  ggplot(aes(x = MathSAT)) +
  geom_histogram() +
  ggtitle("Distribution of DataSet SATGPA") +
  ylab("Frequency") +
  xlab("Score of SAT Math")
```


And here are the results of different outlier tests on the dataset:


```{r}
chi_square(SATGPA$MathSAT, 0.03)
cook_distance(D6)
IQR_test(SATGPA, SATGPA$MathSAT, "MathSAT")
sd_test(SATGPA, SATGPA$MathSAT, "MathSAT")
outlierTest(D6, n.max = Inf)
```


```{r, echo=FALSE, message=FALSE, warning=FALSE}
record <- read_csv("WT Data Record2.csv")
record <- record %>%
  filter(!is.na(N)) %>%
  rename("setName" = "SetName",
         "size" = "Size",
         "n" = "N",
         "distribution" = "Distribution",
         "csq" = "CSQ",
         "cook" = "COOK",
         "iqr" = "IQR",
         "sd" = "SD",
         "bonf" = "BONF") %>%
  mutate(pcsq = csq / n,
         pcook = cook / n,
         piqr = iqr / n,
         psd = sd / n,
         pbonf = bonf / n)
record <- record %>% mutate(id = seq.int(nrow(record)))
```

**Post-Experiment Data:**

Fig. 2:


```{r}
record %>%
  gather(
    key = "methods",
    value = "proportion",
    pcsq, pcook, piqr, psd, pbonf
    ) %>%
  ggplot(aes(x = id, y = proportion, color = methods)) +
  geom_point() +
  facet_wrap(~methods) +
  ylab("Proportion of Outliers") +
  xlab("Number of Datasets") +
  ggtitle("Proportion of Outliers in Each Dataset Detected by Each Method")
```


Fig. 3:


```{r, echo=FALSE, message=FALSE, warning=FALSE}
record %>%
  ggplot(aes(x = id)) +
  geom_line(aes(y = pcsq, color = "csq")) +
  geom_line(aes(y = pcook, color = "cook")) +
  geom_line(aes(y = piqr, color = "iqr")) +
  geom_line(aes(y = psd, color = "sd")) +
  geom_line(aes(y = pbonf, color = "bonf")) +
  scale_color_manual( 
    name = "Method",
    values = c("csq"= "black", "cook" = "blue", "iqr" = "red", "sd" = "green", "bonf" = "orange")) +
  ylab("Proportion of Outliers") +
  xlab("Number of Datasets")
```



Fig. 4:



```{r}
record %>%
  gather(
    key = "methods",
    value = "proportion",
    pcsq, pcook, piqr, psd, pbonf
    ) %>%
  ggplot(aes(x = methods, y = proportion, color = distribution)) +
  geom_boxplot() +
  facet_wrap(~distribution) +
  coord_flip() +
  theme(axis.text.x = element_text(angle=30, hjust=1)) +
  ylab("Proportion of Outliers") +
  xlab("Distribution of Datasets") +
  ggtitle("Boxplot of Outliers Proportion by Different Methods for Different Distributions")
```





Fig. 6: A linear regression of the Standard Deviation Proportion on the IQR Proportion 
```{r, echo=FALSE, message=FALSE}
iqvsd <- glm(piqr~psd, data=record)
gf_point(piqr ~psd,
data = record) %>%
gf_smooth(linetype = "dashed",
color = "red") %>%
gf_lm(size = 1.5)
```

Fig. 7: A linear regression of the Cook's Distance Proportion on the Chis-Square Proportion 
```{r, echo=FALSE}
csvck <- glm(pcook~pcsq, data=record)
gf_point(pcook ~pcsq,
data = record) %>%
gf_smooth(linetype = "dashed",
color = "red") %>%
gf_lm(size = 1.5)
```


```{r, echo=FALSE}
newrecord <- record %>%
  gather(
    key = "methods",
    value = "proportion",
    pcsq, pcook, piqr, psd, pbonf
    )

Good <- newrecord %>% filter(methods == "piqr" | methods == "pcsq")
```



ANOVA on Proportion Methods:
```{r, echo=FALSE}
summary(aov(proportion ~ methods + setName, data=newrecord))

```
There is evidence to show that the means are significantly different.


ANOVA Comparing Proportions of Outliers detected by Chi Square and IQR:
```{r, echo=FALSE}
summary(aov(proportion ~ methods + setName, data=Good))
```
There is no evidence to suggest that the means are significantly different.

**Conclusion:**

After observing the data we can see:

The means of the proportions: (Cook's, Chi-Square, IQR, SD, Bonferroni)
```{r, echo=FALSE}
mean(record$pcook)
mean(record$pcsq)
mean(record$piqr)
mean(record$psd)
mean(record$pbonf)
```
As seen The ANOVA tests, we know that the difference between the mean proportions of methods are significant. We can conclude that these outlier tests work far from identically. The Cook's Distance seems to find the most outliers per dataset whereas the Bonferroni seems to find the least.

When accounting for Skewness, it seems the 






